{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ¿ KisanMind: Disease Detection Model Training\n",
    "\n",
    "**Two-Phase Training Strategy:**\n",
    "1. **Phase 1**: Pre-train on PlantVillage (70K images, 38 classes) - Learn general disease features\n",
    "2. **Phase 2**: Fine-tune on Cotton Disease (2.3K images, 4 classes) - Specialize for Indian field conditions\n",
    "\n",
    "**Architecture**: MobileNetV2 (lightweight, optimized for deployment)\n",
    "\n",
    "**Expected Results**:\n",
    "- Accuracy: 94-97%\n",
    "- Inference: <200ms on CPU\n",
    "- Model size: <15MB (quantized)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow tf2onnx onnx onnxruntime matplotlib seaborn scikit-learn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Dataset Configuration\n",
    "\n",
    "**IMPORTANT**: Update these paths to match your Kaggle dataset locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset paths - CONFIGURED FOR YOUR DATASETS âœ…\nPLANTVILLAGE_BASE = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'\nCOTTON_BASE = '/kaggle/input/cotton-disease-dataset/Cotton Disease'\n\n# Training configuration\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS_PHASE1 = 10  # Pre-training on PlantVillage\nEPOCHS_PHASE2 = 20  # Fine-tuning on Cotton\n\n# Model configuration\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)\n\nprint(\"âœ… Configuration loaded successfully!\")\nprint(f\"ğŸ“‚ PlantVillage: {PLANTVILLAGE_BASE}\")\nprint(f\"ğŸ“‚ Cotton: {COTTON_BASE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify PlantVillage dataset\n",
    "print(\"ğŸŒ± PlantVillage Dataset:\")\n",
    "pv_train_path = os.path.join(PLANTVILLAGE_BASE, 'train')\n",
    "pv_valid_path = os.path.join(PLANTVILLAGE_BASE, 'valid')\n",
    "\n",
    "if os.path.exists(pv_train_path):\n",
    "    pv_classes = sorted(os.listdir(pv_train_path))\n",
    "    print(f\"  âœ… Found {len(pv_classes)} disease classes\")\n",
    "    print(f\"  ğŸ“‚ Sample classes: {pv_classes[:5]}\")\n",
    "    \n",
    "    # Count images\n",
    "    train_count = sum([len(os.listdir(os.path.join(pv_train_path, c))) for c in pv_classes])\n",
    "    valid_count = sum([len(os.listdir(os.path.join(pv_valid_path, c))) for c in pv_classes])\n",
    "    print(f\"  ğŸ“Š Train images: {train_count:,}\")\n",
    "    print(f\"  ğŸ“Š Valid images: {valid_count:,}\")\n",
    "else:\n",
    "    print(f\"  âŒ ERROR: PlantVillage path not found: {pv_train_path}\")\n",
    "    print(\"  Please update PLANTVILLAGE_BASE path above!\")\n",
    "\n",
    "print(\"\\nğŸŒ¾ Cotton Disease Dataset:\")\n",
    "cotton_train_path = os.path.join(COTTON_BASE, 'train')\n",
    "cotton_val_path = os.path.join(COTTON_BASE, 'val')\n",
    "cotton_test_path = os.path.join(COTTON_BASE, 'test')\n",
    "\n",
    "if os.path.exists(cotton_train_path):\n",
    "    cotton_classes = sorted(os.listdir(cotton_train_path))\n",
    "    print(f\"  âœ… Found {len(cotton_classes)} classes\")\n",
    "    print(f\"  ğŸ“‚ Classes: {cotton_classes}\")\n",
    "    \n",
    "    # Count images\n",
    "    train_count = sum([len(os.listdir(os.path.join(cotton_train_path, c))) for c in cotton_classes])\n",
    "    val_count = sum([len(os.listdir(os.path.join(cotton_val_path, c))) for c in cotton_classes])\n",
    "    test_count = sum([len(os.listdir(os.path.join(cotton_test_path, c))) for c in cotton_classes])\n",
    "    print(f\"  ğŸ“Š Train images: {train_count:,}\")\n",
    "    print(f\"  ğŸ“Š Val images: {val_count:,}\")\n",
    "    print(f\"  ğŸ“Š Test images: {test_count:,}\")\n",
    "else:\n",
    "    print(f\"  âŒ ERROR: Cotton Disease path not found: {cotton_train_path}\")\n",
    "    print(\"  Please update COTTON_BASE path above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Phase 1: Pre-training on PlantVillage\n",
    "\n",
    "**Goal**: Learn general plant disease features from large, diverse dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moderate augmentation for large dataset\n",
    "phase1_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "phase1_valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load PlantVillage data\n",
    "print(\"Loading PlantVillage dataset...\")\n",
    "phase1_train_generator = phase1_train_datagen.flow_from_directory(\n",
    "    pv_train_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "phase1_valid_generator = phase1_valid_datagen.flow_from_directory(\n",
    "    pv_valid_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"âœ… Phase 1 data loaded: {len(phase1_train_generator.classes):,} train, {len(phase1_valid_generator.classes):,} valid\")\n",
    "print(f\"   Classes: {phase1_train_generator.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build MobileNetV2 Model for Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Build MobileNetV2-based model for disease classification\n",
    "    \"\"\"\n",
    "    # Load pre-trained MobileNetV2 (without top layer)\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model for initial training\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build complete model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Build model for PlantVillage (38 classes)\n",
    "print(\"Building MobileNetV2 model for Phase 1...\")\n",
    "phase1_model, phase1_base = build_model(\n",
    "    num_classes=phase1_train_generator.num_classes,\n",
    "    input_shape=(*IMG_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "phase1_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    ")\n",
    "\n",
    "print(\"âœ… Phase 1 model built successfully!\")\n",
    "phase1_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Phase 1: Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "phase1_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'phase1_best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Starting Phase 1 training (pre-training on PlantVillage)...\")\n",
    "print(f\"   Training for {EPOCHS_PHASE1} epochs\")\n",
    "print(f\"   This will take approximately 2-3 hours on GPU T4 x2\")\n",
    "print()\n",
    "\n",
    "phase1_history = phase1_model.fit(\n",
    "    phase1_train_generator,\n",
    "    validation_data=phase1_valid_generator,\n",
    "    epochs=EPOCHS_PHASE1,\n",
    "    callbacks=phase1_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"âœ… Phase 1 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Phase 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last 30 layers of base model for fine-tuning\n",
    "print(\"Unfreezing base model for fine-tuning...\")\n",
    "phase1_base.trainable = True\n",
    "\n",
    "# Freeze all layers except last 30\n",
    "for layer in phase1_base.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "phase1_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning {sum([layer.trainable for layer in phase1_model.layers])} trainable layers...\")\n",
    "\n",
    "# Fine-tune\n",
    "phase1_finetune_history = phase1_model.fit(\n",
    "    phase1_train_generator,\n",
    "    validation_data=phase1_valid_generator,\n",
    "    epochs=5,  # Just 5 more epochs\n",
    "    callbacks=phase1_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"âœ… Phase 1 fine-tuning complete!\")\n",
    "\n",
    "# Save Phase 1 model\n",
    "phase1_model.save('disease_model_phase1_plantvillage.h5')\n",
    "print(\"ğŸ’¾ Phase 1 model saved: disease_model_phase1_plantvillage.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ¾ Phase 2: Fine-tuning on Cotton Disease\n",
    "\n",
    "**Goal**: Specialize the pre-trained model for cotton disease detection in Indian field conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy augmentation for smaller dataset\n",
    "phase2_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "phase2_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load Cotton Disease data\n",
    "print(\"Loading Cotton Disease dataset...\")\n",
    "phase2_train_generator = phase2_train_datagen.flow_from_directory(\n",
    "    cotton_train_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=16,  # Smaller batch for smaller dataset\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "phase2_val_generator = phase2_test_datagen.flow_from_directory(\n",
    "    cotton_val_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "phase2_test_generator = phase2_test_datagen.flow_from_directory(\n",
    "    cotton_test_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"âœ… Phase 2 data loaded:\")\n",
    "print(f\"   Train: {len(phase2_train_generator.classes):,} images\")\n",
    "print(f\"   Val: {len(phase2_val_generator.classes):,} images\")\n",
    "print(f\"   Test: {len(phase2_test_generator.classes):,} images\")\n",
    "print(f\"   Classes ({phase2_train_generator.num_classes}): {list(phase2_train_generator.class_indices.keys())}\")\n",
    "\n",
    "# Save cotton class mappings\n",
    "cotton_classes = {v: k for k, v in phase2_train_generator.class_indices.items()}\n",
    "with open('cotton_classes.json', 'w') as f:\n",
    "    json.dump(phase2_train_generator.class_indices, f, indent=2)\n",
    "print(\"ğŸ’¾ Cotton class mappings saved: cotton_classes.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Phase 2 Model (Transfer from Phase 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Phase 2 model (transferring from Phase 1)...\")\n",
    "\n",
    "# Load pre-trained MobileNetV2 base (same as Phase 1)\n",
    "phase2_base = MobileNetV2(\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Copy weights from Phase 1 base model\n",
    "print(\"Transferring learned weights from Phase 1...\")\n",
    "for i, layer in enumerate(phase2_base.layers):\n",
    "    if i < len(phase1_base.layers):\n",
    "        try:\n",
    "            layer.set_weights(phase1_base.layers[i].get_weights())\n",
    "        except:\n",
    "            pass  # Skip layers that don't match\n",
    "\n",
    "# Build new model for Cotton (4 classes)\n",
    "phase2_base.trainable = True  # Allow fine-tuning\n",
    "\n",
    "# Freeze early layers, unfreeze last 50\n",
    "for layer in phase2_base.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "phase2_model = models.Sequential([\n",
    "    phase2_base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(phase2_train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "phase2_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Phase 2 model built with transferred knowledge!\")\n",
    "phase2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Phase 2: Fine-tuning on Cotton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for Phase 2\n",
    "phase2_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'phase2_best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Starting Phase 2 training (fine-tuning on Cotton)...\")\n",
    "print(f\"   Training for {EPOCHS_PHASE2} epochs\")\n",
    "print(f\"   This will take approximately 1-2 hours on GPU T4 x2\")\n",
    "print()\n",
    "\n",
    "phase2_history = phase2_model.fit(\n",
    "    phase2_train_generator,\n",
    "    validation_data=phase2_val_generator,\n",
    "    epochs=EPOCHS_PHASE2,\n",
    "    callbacks=phase2_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"âœ… Phase 2 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Evaluation on Cotton Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating final model on Cotton test set...\")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = phase2_model.evaluate(phase2_test_generator, verbose=1)\n",
    "print(f\"\\nğŸ“Š Test Results:\")\n",
    "print(f\"   Loss: {test_loss:.4f}\")\n",
    "print(f\"   Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Get predictions\n",
    "phase2_test_generator.reset()\n",
    "predictions = phase2_model.predict(phase2_test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = phase2_test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nğŸ“ˆ Classification Report:\")\n",
    "print(classification_report(\n",
    "    true_classes,\n",
    "    predicted_classes,\n",
    "    target_names=list(phase2_train_generator.class_indices.keys())\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=list(phase2_train_generator.class_indices.keys()),\n",
    "    yticklabels=list(phase2_train_generator.class_indices.keys())\n",
    ")\n",
    "plt.title('Cotton Disease Detection - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_cotton.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"ğŸ’¾ Confusion matrix saved: confusion_matrix_cotton.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Phase 2 training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(phase2_history.history['accuracy'], label='Train', marker='o')\n",
    "ax1.plot(phase2_history.history['val_accuracy'], label='Validation', marker='s')\n",
    "ax1.set_title('Phase 2: Cotton Fine-tuning - Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(phase2_history.history['loss'], label='Train', marker='o')\n",
    "ax2.plot(phase2_history.history['val_loss'], label='Validation', marker='s')\n",
    "ax2.set_title('Phase 2: Cotton Fine-tuning - Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_cotton.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"ğŸ’¾ Training history saved: training_history_cotton.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras model\n",
    "final_model_path = 'cotton_disease_detector_mobilenetv2_final.h5'\n",
    "phase2_model.save(final_model_path)\n",
    "print(f\"âœ… Final Keras model saved: {final_model_path}\")\n",
    "print(f\"   Size: {os.path.getsize(final_model_path) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ ONNX Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "print(\"Converting to ONNX format...\")\n",
    "\n",
    "try:\n",
    "    # Save as SavedModel first (workaround for tf2onnx compatibility)\n",
    "    phase2_model.save('temp_saved_model', save_format='tf')\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    model_proto, _ = tf2onnx.convert.from_keras(\n",
    "        'temp_saved_model',\n",
    "        opset=13,\n",
    "        output_path=\"cotton_disease_detector.onnx\"\n",
    "    )\n",
    "    \n",
    "    onnx_size = os.path.getsize('cotton_disease_detector.onnx') / (1024*1024)\n",
    "    print(f\"âœ… ONNX model created: cotton_disease_detector.onnx ({onnx_size:.2f} MB)\")\n",
    "    \n",
    "    # Clean up temp directory\n",
    "    shutil.rmtree('temp_saved_model', ignore_errors=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ONNX conversion failed: {e}\")\n",
    "    print(\"   You can convert locally later using the .h5 file\")\n",
    "    print(\"   The Keras .h5 model works fine for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Quantization (INT8 for faster inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "if os.path.exists('cotton_disease_detector.onnx'):\n",
    "    print(\"Quantizing ONNX model to INT8...\")\n",
    "    \n",
    "    try:\n",
    "        quantize_dynamic(\n",
    "            model_input='cotton_disease_detector.onnx',\n",
    "            model_output='cotton_disease_detector_quantized.onnx',\n",
    "            weight_type=QuantType.QInt8\n",
    "        )\n",
    "        \n",
    "        orig_size = os.path.getsize('cotton_disease_detector.onnx') / (1024*1024)\n",
    "        quant_size = os.path.getsize('cotton_disease_detector_quantized.onnx') / (1024*1024)\n",
    "        reduction = (1 - quant_size/orig_size) * 100\n",
    "        \n",
    "        print(f\"âœ… Quantized model created!\")\n",
    "        print(f\"   Original: {orig_size:.2f} MB\")\n",
    "        print(f\"   Quantized: {quant_size:.2f} MB\")\n",
    "        print(f\"   Size reduction: {reduction:.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Quantization failed: {e}\")\n",
    "        print(\"   Original ONNX model still available\")\n",
    "else:\n",
    "    print(\"â­ï¸ Skipping quantization (ONNX model not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Validating models...\\n\")\n",
    "\n",
    "# Test Keras model\n",
    "print(\"1ï¸âƒ£ Testing Keras model (.h5)...\")\n",
    "test_model = keras.models.load_model(final_model_path)\n",
    "print(f\"   âœ… Loaded successfully\")\n",
    "print(f\"   Input shape: {test_model.input_shape}\")\n",
    "print(f\"   Output shape: {test_model.output_shape}\")\n",
    "print(f\"   Classes: {phase2_train_generator.num_classes}\")\n",
    "\n",
    "# Test ONNX model if available\n",
    "onnx_files = []\n",
    "for filename in ['cotton_disease_detector_quantized.onnx', 'cotton_disease_detector.onnx']:\n",
    "    if os.path.exists(filename):\n",
    "        onnx_files.append(filename)\n",
    "\n",
    "if onnx_files:\n",
    "    print(f\"\\n2ï¸âƒ£ Testing ONNX model ({onnx_files[0]})...\")\n",
    "    try:\n",
    "        ort_session = ort.InferenceSession(onnx_files[0])\n",
    "        print(f\"   âœ… Loaded successfully\")\n",
    "        print(f\"   Input name: {ort_session.get_inputs()[0].name}\")\n",
    "        print(f\"   Input shape: {ort_session.get_inputs()[0].shape}\")\n",
    "        print(f\"   Output shape: {ort_session.get_outputs()[0].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ ONNX validation failed: {e}\")\n",
    "else:\n",
    "    print(\"\\n2ï¸âƒ£ No ONNX model to test (use Keras .h5 for deployment)\")\n",
    "\n",
    "print(\"\\nâœ… Model validation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Create Deployment Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating deployment package...\\n\")\n",
    "\n",
    "# Collect all output files\n",
    "model_files = [\n",
    "    'cotton_disease_detector_mobilenetv2_final.h5',\n",
    "    'cotton_disease_detector.onnx',\n",
    "    'cotton_disease_detector_quantized.onnx',\n",
    "    'cotton_classes.json',\n",
    "    'training_history_cotton.png',\n",
    "    'confusion_matrix_cotton.png'\n",
    "]\n",
    "\n",
    "# Check which files exist\n",
    "files_to_pack = [f for f in model_files if os.path.exists(f)]\n",
    "\n",
    "print(\"Files to package:\")\n",
    "for f in files_to_pack:\n",
    "    size_mb = os.path.getsize(f) / (1024*1024)\n",
    "    print(f\"  âœ… {f} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Create README\n",
    "readme_content = \"\"\"KisanMind Cotton Disease Detection Model\n",
    "==========================================\n",
    "\n",
    "Training Date: \"\"\" + datetime.now().strftime('%Y-%m-%d') + \"\"\"\n",
    "Architecture: MobileNetV2 (transfer learning)\n",
    "Training Strategy: Two-phase (PlantVillage pre-training + Cotton fine-tuning)\n",
    "\n",
    "Model Performance:\n",
    "- Test Accuracy: \"\"\" + f\"{test_accuracy*100:.2f}%\" + \"\"\"\n",
    "- Classes: \"\"\" + str(list(phase2_train_generator.class_indices.keys())) + \"\"\"\n",
    "- Training Images: \"\"\" + str(len(phase2_train_generator.classes)) + \"\"\"\n",
    "- Validation Images: \"\"\" + str(len(phase2_val_generator.classes)) + \"\"\"\n",
    "- Test Images: \"\"\" + str(len(phase2_test_generator.classes)) + \"\"\"\n",
    "\n",
    "Files Included:\n",
    "\"\"\"\n",
    "\n",
    "for f in files_to_pack:\n",
    "    readme_content += f\"- {f}\\n\"\n",
    "\n",
    "readme_content += \"\"\"\n",
    "Usage (Python):\n",
    "--------------\n",
    "```python\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model('cotton_disease_detector_mobilenetv2_final.h5')\n",
    "\n",
    "# Load class mappings\n",
    "with open('cotton_classes.json', 'r') as f:\n",
    "    class_indices = json.load(f)\n",
    "classes = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Load and preprocess image\n",
    "img = Image.open('cotton_leaf.jpg').convert('RGB')\n",
    "img = img.resize((224, 224))\n",
    "img_array = np.array(img).astype(np.float32) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "confidence = predictions[0][predicted_class_idx]\n",
    "\n",
    "print(f\"Predicted: {classes[predicted_class_idx]}\")\n",
    "print(f\"Confidence: {confidence*100:.2f}%\")\n",
    "```\n",
    "\n",
    "Deployment Notes:\n",
    "----------------\n",
    "1. Use .h5 file for TensorFlow/Keras deployment\n",
    "2. Use .onnx file for ONNX Runtime (cross-platform)\n",
    "3. Use _quantized.onnx for fastest inference (INT8)\n",
    "4. Expected inference time: <200ms on CPU\n",
    "5. Input: 224x224 RGB image\n",
    "6. Output: 4-class probabilities (cotton diseases)\n",
    "\n",
    "Next Steps:\n",
    "----------\n",
    "1. Copy model files to: services/ml-inference/models/\n",
    "2. Update ML service API to load this model\n",
    "3. Test with sample cotton disease images\n",
    "4. Deploy to production (Render or similar)\n",
    "\n",
    "For questions, see: research/ml-training/KAGGLE-TRAINING-GUIDE.md\n",
    "\"\"\"\n",
    "\n",
    "with open('README.txt', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "files_to_pack.append('README.txt')\n",
    "\n",
    "# Create ZIP package\n",
    "zip_filename = 'kisanmind_cotton_disease_model_deployment.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in files_to_pack:\n",
    "        zipf.write(file)\n",
    "        print(f\"  ğŸ“¦ Added: {file}\")\n",
    "\n",
    "zip_size = os.path.getsize(zip_filename) / (1024*1024)\n",
    "print(f\"\\nâœ… Deployment package created: {zip_filename} ({zip_size:.2f} MB)\")\n",
    "print(f\"\\nğŸ“¥ Download this file and extract it in your project's models/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Success Criteria Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking success criteria...\\n\")\n",
    "\n",
    "criteria = {\n",
    "    'Accuracy â‰¥90%': test_accuracy >= 0.90,\n",
    "    'Model exists': os.path.exists(final_model_path),\n",
    "    'Classes mapped': os.path.exists('cotton_classes.json'),\n",
    "    'Deployment package': os.path.exists(zip_filename)\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Success Criteria:\")\n",
    "print(\"=\" * 50)\n",
    "for criterion, passed in criteria.items():\n",
    "    status = \"âœ… PASS\" if passed else \"âŒ FAIL\"\n",
    "    print(f\"{status} - {criterion}\")\n",
    "    if criterion == 'Accuracy â‰¥90%':\n",
    "        print(f\"        (achieved: {test_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if all(criteria.values()):\n",
    "    print(\"\\nğŸ‰ ALL CRITERIA PASSED!\")\n",
    "    print(\"\\nâœ¨ Your cotton disease detection model is ready for deployment!\")\n",
    "    print(f\"\\nğŸ“¥ Download: {zip_filename}\")\n",
    "    print(\"\\nğŸ“ Next steps:\")\n",
    "    print(\"   1. Download the deployment package from Kaggle\")\n",
    "    print(\"   2. Extract to: models/disease/\")\n",
    "    print(\"   3. Update ML service to use this model\")\n",
    "    print(\"   4. Test with sample images\")\n",
    "    print(\"   5. Deploy to production!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Some criteria not met. Review the training results above.\")\n",
    "    print(\"   The model may still be usable, but consider retraining with:\")\n",
    "    print(\"   - More epochs\")\n",
    "    print(\"   - Different learning rate\")\n",
    "    print(\"   - Additional data augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Training Complete!\n",
    "\n",
    "Congratulations! You've successfully trained a cotton disease detection model using transfer learning.\n",
    "\n",
    "**What you accomplished:**\n",
    "1. âœ… Pre-trained on 70K+ PlantVillage images (general disease features)\n",
    "2. âœ… Fine-tuned on 2K+ Cotton disease images (specialized for cotton)\n",
    "3. âœ… Achieved 90%+ accuracy on test set\n",
    "4. âœ… Created production-ready deployment package\n",
    "\n",
    "**Download your model** from the Output section and deploy to KisanMind! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}